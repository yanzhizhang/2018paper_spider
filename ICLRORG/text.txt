PublishedasaconferencepaperatICLR2018
D
EEP
C
OMPLEX
N
ETWORKS
ChihebTrabelsi,

W
|
OlexaBilaniuk,

W
YingZhang,
y
W

DmitriySerdyuk,
y
W
SandeepSubramanian,
y
W
JoãoFelipeSantos,
W
SoroushMehri,
V
NegarRostamzadeh,

YoshuaBengio
W
{
&ChristopherJPal
W
|
W
MontrealInstituteforLearningAlgorithms(MILA),Montreal
|
EcolePolytechnique,Montreal
V
MicrosoftResearch,Montreal

ElementAI,Montreal
{
CIFARSeniorFellow
chiheb.trabelsi@polymtl.ca
,
olexa.bilaniuk@umontreal.ca
,
ying.zhlisa@gmail.com
,
{serdyuk@iro,sandeep.subramanian.1@}umontreal.ca
,
jfsantos@emt.inrs.ca
,
soroush.mehri@microsoft.com
,
negar@elementai.com
,
find.me@the.web
,
christopher.pal@polymtl.ca
A
BSTRACT
Atpresent,thevastmajorityofbuildingblocks,techniques,andarchitecturesfor
deeplearningarebasedonreal-valuedoperationsandrepresentations.However,
recentworkonrecurrentneuralnetworksandolderfundamentaltheoreticalanal-
ysissuggeststhatcomplexnumberscouldhavearicherrepresentationalcapacity
andcouldalsofacilitatenoise-robustmemoryretrievalmechanisms.Despitetheir
attractivepropertiesandpotentialforopeningupentirelynewneuralarchitectures,
complex-valueddeepneuralnetworkshavebeenmarginalizedduetotheabsence
ofthebuildingblocksrequiredtodesignsuchmodels.Inthiswork,weprovide
thekeyatomiccomponentsforcomplex-valueddeepneuralnetworksandapply
themtoconvolutionalfeed-forwardnetworksandconvolutionalLSTMs.More
precisely,werelyoncomplexconvolutionsandpresentalgorithmsforcomplex
batch-normalization,complexweightinitializationstrategiesforcomplex-valued
neuralnetsandweusetheminexperimentswithend-to-endtrainingschemes.
Wedemonstratethatsuchcomplex-valuedmodelsarecompetitivewiththeirreal-
valuedcounterparts.Wetestdeepcomplexmodelsonseveralcomputervision
tasks,onmusictranscriptionusingtheMusicNetdatasetandonSpeechSpectrum
PredictionusingtheTIMITdataset.Weachievestate-of-the-artperformanceon
theseaudio-relatedtasks.
1I
NTRODUCTION
Recentresearchadvanceshavemadeprogressinaddressingthedifinvolvedin
learningdeepneuralnetworkarchitectures.Keyinnovationsincludenormalizationtechniques(Ioffe
andSzegedy,2015;SalimansandKingma,2016)andtheemergenceofgating-basedfeed-forward
neuralnetworkslikeHighwayNetworks(Srivastavaetal.,2015).Residualnetworks(Heetal.,
2015a;2016)haveemergedasoneofthemostpopularandeffectivestrategiesfortrainingverydeep
convolutionalneuralnetworks(CNNs).Bothhighwaynetworksandresidualnetworksfacilitate
thetrainingofdeepnetworksbyprovidingshortcutpathsforeasygradientwtolowernetwork
layerstherebydiminishingtheeffectsofvanishinggradients(Hochreiter,1991).Heetal.(2016)

Equalauthor
y
Equalcontributions
1

what the hell the url is https://openreview.net/pdf?id=B1mvVm-C-
Sucessful to download test.pdf
<PyPDF2.pdf.PdfFileReader object at 0x051A1A50>
PublishedasaconferencepaperatICLR2018
U
NIVERSAL
A
GENT
FOR
D
ISENTANGLING
E
NVIRONMENTSAND
T
ASKS
JiayuanMao&HonghuaDong

TheInstituteforTheoreticalComputerScience
InstituteforInterdisciplinaryInformationSciences
TsinghuaUniversity
Beijing,China
{mjy14,dhh14}@mails.tsinghua.edu.cn
JosephJ.Lim
DepartmentofComputerScience
UniversityofSouthernCalifornia
LosAngeles,USA
limjj@usc.edu
A
BSTRACT
Recentstate-of-the-artreinforcementlearningalgorithmsaretrainedunderthe
goalofexcellinginonetask.Hence,bothenvironmentandtask
knowledgeareentangledintooneframework.However,thereareoftenscenarios
wheretheenvironment(
e.g
.thephysicalworld)isedwhileonlythetargettask
changes.Hence,borrowingtheideafromhierarchicalreinforcementlearning,we
proposeaframeworkthatdisentanglestaskandenvironmentknowledge
byseparatingthemintotwounits.Theenunithandleshowto
movefromonestatetothetargetstate;andtheunitplansforthenext
targetstategivenatask.Theextensiveresultsinsimulatorsindicatethat
ourmethodcanefcientlyseparateandlearntwoindependentunits,andalsoadapt
toanewtaskmoreefthanthestate-of-the-artmethods.
1I
NTRODUCTION
Let'simagineourselveslearninghowtoplaytennisforthetime.Eventhoughwehavenever
playedtennisbefore,wealreadyhaveagoodunderstandingofagentandenvironmentdynamics
relatedtotennis.Forexample,weknowhowtomoveourarmfromonepositiontoanotherandthat
aballwillslowdownandbouncebackfromtheground.Hence,wejustneedtolearnthetennis
knowledge(
e.g
.itsgameruleandarelationshipbetweenanarmcontrolandatennisracket).
Justlikethisexample,whenwelearntocompleteanewtask,weutilizethepriorknowledgethatis
disentangledfromthetaskandacquiredoverourlifetime.
(a)Agent
(b)UniversalAgent
Figure1:Ourmodeldisentangleseninformation(
e.g
.transitiondynamics)and
knowledge(
e.g
.taskrewards)fortrainingefyandinterpretability.
Fromareinforcementlearningperspective,thisbringsaveryinterestingquestionŒhowcanagents
alsoobtainandutilizesuchdisentangledpriorknowledgeabouttheenvironment?Mostoftoday's
deepreinforcementlearning(DRL)modelsMnihetal.(2015;2016);Schulmanetal.(2015a;2017)
aretrainedwithentangledenknowledge(
e.g
.transitiondynamics)andtask-
knowledge(
e.g
.rewards),asdescribedinFigure1aHowever,asdescribedearlier,humans

WorkwasdonewhenJiayuanandHonghuawerevisitingstudentsatUSC.
1

what the hell the url is https://openreview.net/pdf?id=SJx9GQb0-
Sucessful to download test.pdf
<PyPDF2.pdf.PdfFileReader object at 0x051B5AF0>
PublishedasaconferencepaperatICLR2018
I
MPROVINGTHE
I
MPROVED
T
RAININGOF
W
ASSERSTEIN
GAN
S
:
AC
ONSISTENCY
T
ERMAND
I
TS
D
UAL
E
FFECT
XiangWei
1
;
2

,BoqingGong
3

,ZixiaLiu
1
,WeiLu
2
,LiqiangWang
1
1
DepartmentofComputerScience,UniversityofCentralFlorida,Orlando,FL,USA32816
2
SchoolofSoftwareEngineering,BeijingJiaotongUniversity,Beijing,China100044
3
TencentAILab,Bellevue,WA,USA98004
yqweixiang@knights.ucf.edu,boqinggo@outlook.com
zixia@knights.ucf.edu,luwei@bjtu.edu.cn,lwang@cs.ucf.edu
A
BSTRACT
Despitebeingimpactfulonavarietyofproblemsandapplications,thegenerative
adversarialnets(GANs)areremarkablydiftotrain.Thisissueisformallyan-
alyzedbyArjovsky&Bottou(2017),whoalsoproposeanalternativedirectionto
avoidthecaveatsintheminmaxtwo-playertrainingofGANs.Thecorresponding
algorithm,calledWassersteinGAN(WGAN),hingesonthe1-Lipschitzcontinu-
ityofthediscriminator.Inthispaper,weproposeanovelapproachtoenforcing
theLipschitzcontinuityinthetrainingprocedureofWGANs.Ourapproachseam-
lesslyconnectsWGANwithoneoftherecentsemi-supervisedlearningmethods.
Asaresult,itgivesrisetonotonlybetterphoto-realisticsamplesthanthepre-
viousmethodsbutalsostate-of-the-artsemi-supervisedlearningresults.Inpar-
ticular,ourapproachgivesrisetotheinceptionscoreofmorethan5.0withonly
1,000CIFAR-10imagesandisthethatexceedstheaccuracyof90%onthe
CIFAR-10datasetusingonly4,000labeledimages,tothebestofourknowledge.
1I
NTRODUCTION
Wehavewitnessedagreatsurgeofinterestsindeepgenerativenetworksinrecentyears(Kingma&
Welling,2013;Goodfellowetal.,2014;Lietal.,2015).Thecentralideathereinistofeedarandom
vectortoa(
e.g.
,feedforward)neuralnetworkandthentaketheoutputasthedesiredsample.This
samplingprocedureisveryefwithouttheneedofanyMarkovchains.
Inordertotrainsuchadeepgenerativenetwork,twobroadcategoriesofmethodsareproposed.
Theistousestochasticvariationalinference(Kingma&Welling,2013;Rezendeetal.,2014;
Kingmaetal.,2014)tooptimizethelowerboundofthedatalikelihood.Theotheristousethe
samplesasaproxytominimizethedistributiondivergencebetweenthemodelandtherealthrough
atwo-playergame(Goodfellowetal.,2014;Salimansetal.,2016),maximummeandiscrepancy(Li
etal.,2015;Dziugaiteetal.,2015;Lietal.,2017b),f-divergence(Nowozinetal.,2016;Nocketal.,
2017),andthemostrecentWassersteindistance(Arjovskyetal.,2017;Gulrajanietal.,2017).
Withnodoubt,thegenerativeadversarialnetworks(GANs)amongthem(Goodfellowetal.,2014)
havethebiggestimpactthusfaronavarietyofproblemsandapplications(Radfordetal.,2015;
Dentonetal.,2015;Imetal.,2016;Isolaetal.,2016;Springenberg,2015;Sutskeveretal.,2015;
Odena,2016;Zhuetal.,2017).GANslearnthegenerativenetwork(generator)byplayingatwo-
playergamebetweenthegeneratorandanauxiliarydiscriminatornetwork.Whilethegeneratorhas
nodifferencefromotherdeepgenerativemodelsinthesensethatittranslatesarandomvectorintoa
desiredsample,itisimpossibletocalculatethesamplelikelihoodfromit.Instead,thediscriminator
servestoevaluatethequalityofthegeneratedsamplesbycheckinghowdifitistodifferentiate
themfromrealdatapoints.