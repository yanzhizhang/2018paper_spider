Published as a conference paper at ICLR 2018

HIERARCHICAL SUBTASK DISCOVERY
WITH NON-NEGATIVE MATRIX FACTORIZATION

Adam C. Earle
Department of Computer Science and Applied Mathematics
University of the Witwatersrand
Johannesburg, South Africa
adam.earle@students.wits.ac.za

Andrew M. Saxe
Center for Brain Science
Harvard University
MA, USA
asaxe@fas.harvard.edu

Benjamin Rosman
Council for Scientiﬁc and Industrial Research
Pretoria, South Africa, and
Department of Computer Science and Applied Mathematics
University of the Witwatersrand
Johannesburg, South Africa
brosman@csir.co.za

ABSTRACT

Hierarchical reinforcement learning methods offer a powerful means of planning
ﬂexible behavior in complicated domains. However, learning an appropriate hierar-
chical decomposition of a domain into subtasks remains a substantial challenge. We
present a novel algorithm for subtask discovery, based on the recently introduced
multitask linearly-solvable Markov decision process (MLMDP) framework. The
MLMDP can perform never-before-seen tasks by representing them as a linear
combination of a previously learned basis set of tasks. In this setting, the subtask
discovery problem can naturally be posed as ﬁnding an optimal low-rank approx-
imation of the set of tasks the agent will face in a domain. We use non-negative
matrix factorization to discover this minimal basis set of tasks, and show that the
technique learns intuitive decompositions in a variety of domains. Our method has
several qualitatively desirable features: it is not limited to learning subtasks with
single goal states, instead learning distributed patterns of preferred states; it learns
qualitatively different hierarchical decompositions in the same domain depending
on the ensemble of tasks the agent will face; and it may be straightforwardly
iterated to obtain deeper hierarchical decompositions.

1

INTRODUCTION

Hierarchical reinforcement learning methods hold the promise of faster learning in complex state
spaces and better transfer across tasks, by exploiting planning at multiple levels of detail (Barto
& Madadevan, 2003). A taxi driver, for instance, ultimately must execute a policy in the space of
torques and forces applied to the steering wheel and pedals, but planning directly at this low level is
beset by the curse of dimensionality. Algorithms like HAMS, MAXQ, and the options framework
permit powerful forms of hierarchical abstraction, such that the taxi driver can plan at a higher level,
perhaps choosing which passengers to pick up or a sequence of locations to navigate to (Sutton et al.,
1999; Dietterich, 2000; Parr & Russell, 1998). While these algorithms can overcome the curse of
dimensionality, they require the designer to specify the set of higher level actions or subtasks available

1

