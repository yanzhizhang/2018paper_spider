Published as a conference paper at ICLR 2018

SCAN: LEARNING HIERARCHICAL
COMPOSITIONAL VISUAL CONCEPTS

Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal,
Christopher P Burgess, Matko Bošnjak, Murray Shanahan,
Matthew Botvinick, Demis Hassabis, Alexander Lerchner
DeepMind, London, UK
{irinah,sonnerat,lmatthey,arkap,cpburgess,
matko,botvinick,demishassabis,lerchner}@google.com

ABSTRACT

The seemingly inﬁnite diversity of the natural world arises from a relatively small
set of coherent rules, such as the laws of physics or chemistry. We conjecture that
these rules give rise to regularities that can be discovered through primarily unsuper-
vised experiences and represented as abstract concepts. If such representations are
compositional and hierarchical, they can be recombined into an exponentially large
set of new concepts. This paper describes SCAN (Symbol-Concept Association
Network), a new framework for learning such abstractions in the visual domain.
SCAN learns concepts through fast symbol association, grounding them in disen-
tangled visual primitives that are discovered in an unsupervised manner. Unlike
state of the art multimodal generative model baselines, our approach requires very
few pairings between symbols and images and makes no assumptions about the
form of symbol representations. Once trained, SCAN is capable of multimodal
bi-directional inference, generating a diverse set of image samples from symbolic
descriptions and vice versa. It also allows for traversal and manipulation of the
implicit hierarchy of visual concepts through symbolic instructions and learnt
logical recombination operations. Such manipulations enable SCAN to break
away from its training data distribution and imagine novel visual concepts through
symbolically instructed recombination of previously learnt concepts.

1

INTRODUCTION

State of the art deep learning approaches to machine learning have achieved impressive results in
many problem domains, including classiﬁcation (He et al., 2016; Szegedy et al., 2015), density
modelling (Gregor et al., 2015; Oord et al., 2016a;b), and reinforcement learning (Mnih et al., 2015;
2016; Jaderberg et al., 2017; Silver et al., 2016). They are still, however, far from possessing many
traits characteristic of human intelligence. Such deep learning techniques tend to be overly data
hungry, often rely on signiﬁcant human supervision and tend to overﬁt to the training data distribution
(Lake et al., 2016; Garnelo et al., 2016). An important step towards bridging the gap between human
and artiﬁcial intelligence is endowing algorithms with compositional concepts (Lake et al., 2016;
Garnelo et al., 2016). Compositionality allows for reuse of a ﬁnite set of primitives (addressing the
data efﬁciency and human supervision issues) across many scenarios by recombining them to produce
an exponentially large number of novel yet coherent and potentially useful concepts (addressing the
overﬁtting problem). Compositionality is at the core of such human abilities as creativity, imagination
and language-based communication.
We propose that concepts are abstractions over a set of primitives. For example, consider a toy
hierarchy of visual concepts shown in Fig. 1. Each node in this hierarchy is deﬁned as a subset of
visual primitives that make up the scene in the input image. These visual primitives might include
factors like object identity, object colour, ﬂoor colour and wall colour. As one traverses the hierarchy
from the subordinate over basic to superordinate levels of abstraction (Rosch, 1978) (i.e. from the
more speciﬁc to the more general concepts corresponding to the same visual scene), the number of
concept-deﬁning visual primitives decreases. Hence, each parent concept in such a hierarchy is an

1

