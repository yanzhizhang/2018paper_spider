Published as a conference paper at ICLR 2018

SIMULATED+UNSUPERVISED LEARNING WITH
ADAPTIVE DATA GENERATION AND
BIDIRECTIONAL MAPPINGS

Kangwook Lee∗, Hoon Kim∗& Changho Suh
School of Electrical Engineering
KAIST
Daejeon, South Korea
{kw1jjang,gnsrla12,chsuh}@kaist.ac.kr

ABSTRACT

Collecting a large dataset with high quality annotations is expensive and time-
consuming. Recently, Shrivastava et al. (2017) propose Simulated+Unsupervised
(S+U) learning: It ﬁrst learns a mapping from synthetic data to real data, trans-
lates a large amount of labeled synthetic data to the ones that resemble real data,
and then trains a learning model on the translated data. Bousmalis et al. (2017b)
propose a similar framework that jointly trains a translation mapping and a learn-
ing model. While these algorithms are shown to achieve the state-of-the-art per-
formances on various tasks, it may have a room for improvement, as they do
not fully leverage ﬂexibility of data simulation process and consider only the for-
ward (synthetic to real) mapping. Inspired by this limitation, we propose a new
S+U learning algorithm, which fully leverage the ﬂexibility of data simulators
and bidirectional mappings between synthetic and real data. We show that our
approach achieves the improved performance on the gaze estimation task, outper-
forming (Shrivastava et al., 2017).

1

INTRODUCTION

Collecting a large annotated dataset is usually a very expensive and time-consuming task, and some-
times it is even infeasible. Recently, researchers have proposed the use of synthetic datasets provided
by simulators to address this challenge. Not only synthetic datasets can be easily annotated but one
can also generate an arbitrarily large amount of synthetic data. In addition to that, recent advances
in computer technologies enabled synthesis of high-quality data.
Speciﬁcally, a variety of computer vision applications have beneﬁtted from advanced computer
graphics technologies. For instance, Wood et al. (2016) manipulate a 3D game graphics engine,
called Unity, to synthesize photo-realistic images of human eye regions. Then, using a million
of synthetic images with labels, they achieve the state-of-the-art performance on the cross-domain
appearance-based gaze estimation task (Sugano et al., 2014). Another important application that
is heavily beneﬁtting from synthetic data is autonomous driving. A few recent works show that
an inﬁnite amount of realistic driving data can be collected from high-quality video games such
as GTA V (Grand Theft Auto V) (Richter et al., 2016; Johnson-Roberson et al., 2017; Lee et al.,
2017). Speciﬁcally, Richter et al. (2016) show that a semantic segmentation model trained only with
synthetic data can even outperform the model trained with real data if the amount of synthetic data
is large enough. In (Lee et al., 2017), the authors collect a synthetic dataset of vehicle accidents,
which is hardly collectable from the real world, train an accident prediction model with the syn-
thetic data, and then apply the trained model to a real accident dataset. As a result, they show that
the model trained with large synthetic dataset can outperform the model trained within small real
dataset. Further, researchers also propose the use of simulated environments for building algorithms
for autonomous drones (Microsoft, 2017), autonomous truck driving (Im, 2017), etc.

∗These two authors contributed equally

1

