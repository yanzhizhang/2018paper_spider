Published as a conference paper at ICLR 2018

THE ROLE OF MINIMAL COMPLEXITY FUNCTIONS IN
UNSUPERVISED LEARNING OF SEMANTIC MAPPINGS

Lior Wolf
Facebook AI Research &
The Blavatnik School of Computer Science
Tel Aviv University
Tel Aviv, Israel
wolf@fb.com
wolf@cs.tau.ac.il

Tomer Galanti
The Blavatnik School of Computer Science
Tel Aviv University
Tel Aviv, Israel
tomerga2@post.tau.ac.il

Sagie Benaim
The Blavatnik School of Computer Science
Tel Aviv University
Tel Aviv, Israel
sagieb@mail.tau.ac.il

ABSTRACT

We discuss the feasibility of the following learning problem: given unmatched
samples from two domains and nothing else, learn a mapping between the two,
which preserves semantics. Due to the lack of paired samples and without any deﬁ-
nition of the semantic information, the problem might seem ill-posed. Speciﬁcally,
in typical cases, it seems possible to build inﬁnitely many alternative mappings
from every target mapping. This apparent ambiguity stands in sharp contrast to the
recent empirical success in solving this problem.
We identify the abstract notion of aligning two domains in a semantic way with
concrete terms of minimal relative complexity. A theoretical framework for mea-
suring the complexity of compositions of functions is developed in order to show
that it is reasonable to expect the minimal complexity mapping to be unique. The
measured complexity used is directly related to the depth of the neural networks
being learned and a semantically aligned mapping could then be captured simply by
learning using architectures that are not much bigger than the minimal architecture.
Various predictions are made based on the hypothesis that semantic alignment can
be captured by the minimal mapping. These are veriﬁed extensively. In addition, a
new mapping algorithm is proposed and shown to lead to better mapping results.

1

INTRODUCTION

Multiple recent reports (Xia et al., 2016; Kim et al., 2017; Zhu et al., 2017; Yi et al., 2017) convincingly
demonstrated that one can learn to map between two domains that are each speciﬁed merely by a set
of unlabeled examples. For example, given a set of unlabeled images of horses, and a set of unlabeled
images of zebras, CycleGAN (Zhu et al., 2017) creates the analog zebra image for a new image of a
horse and vice versa.
These recent methods employ two types of constraints. First, when mapping from one domain
to another, the output has to be indistinguishable from the samples of the new domain. This is
enforced using GANs (Goodfellow et al., 2014) and is applied at the distribution level: the mapping
of horse images to the zebra domain should create images that are indistinguishable from the training
images of zebras and vice versa. The second type of constraint enforces that for every single sample,
transforming it to the other domain and back (by a composition of the mappings in the two directions)
results in the original sample. This is enforced for each training sample from either domain: every
training image of a horse (zebra), which is mapped to a zebra (horse) image and then back to the
source domain, should be as similar as possible to the original input image.

1

