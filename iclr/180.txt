Published as a conference paper at ICLR 2018

MEASURING THE INTRINSIC DIMENSION
OF OBJECTIVE LANDSCAPES

Chunyuan Li ∗
Duke University
cl319@duke.edu

Heerad Farkhoor, Rosanne Liu, and Jason Yosinski
Uber AI Labs
{heerad,rosanne,yosinski}@uber.com

ABSTRACT

Many recently trained neural networks employ large numbers of parameters to
achieve good performance. One may intuitively use the number of parameters
required as a rough gauge of the difﬁculty of a problem. But how accurate are
such notions? How many parameters are really needed? In this paper we at-
tempt to answer this question by training networks not in their native parameter
space, but instead in a smaller, randomly oriented subspace. We slowly increase
the dimension of this subspace, note at which dimension solutions ﬁrst appear,
and deﬁne this to be the intrinsic dimension of the objective landscape. The ap-
proach is simple to implement, computationally tractable, and produces several
suggestive conclusions. Many problems have smaller intrinsic dimensions than
one might suspect, and the intrinsic dimension for a given dataset varies little
across a family of models with vastly different sizes. This latter result has the
profound implication that once a parameter space is large enough to solve a prob-
lem, extra parameters serve directly to increase the dimensionality of the solution
manifold. Intrinsic dimension allows some quantitative comparison of problem
difﬁculty across supervised, reinforcement, and other types of learning where we
conclude, for example, that solving the inverted pendulum problem is 100 times
easier than classifying digits from MNIST, and playing Atari Pong from pixels
is about as hard as classifying CIFAR-10. In addition to providing new cartogra-
phy of the objective landscapes wandered by parameterized models, the method
is a simple technique for constructively obtaining an upper bound on the mini-
mum description length of a solution. A byproduct of this construction is a simple
approach for compressing networks, in some cases by more than 100 times.

1

INTRODUCTION

Training a neural network to model a given dataset entails several steps. First, the network designer
chooses a loss function and a network architecture for a given dataset. The architecture is then ini-
tialized by populating its weights with random values drawn from some distribution. Finally, the
network is trained by adjusting its weights to produce a loss as low as possible. We can think of
the training procedure as traversing some path along an objective landscape. Note that as soon as
a dataset and network architecture are speciﬁed, the landscape in its entirety is completely deter-
mined. It is instantiated and frozen; all subsequent parameter initialization, forward and backward
propagation, and gradient steps taken by an optimizer are just details of how the frozen space is
explored.
Consider a network parameterized by D weights. We can picture its associated objective landscape
as a set of “hills and valleys” in D dimensions, where each point in RD corresponds to a value of the
loss, i.e., the elevation of the landscape. If D = 2, the map from two coordinates to one scalar loss
can be easily imagined and intuitively understood by those living in a three-dimensional world with
similar hills. However, in higher dimensions, our intuitions may not be so faithful, and generally we
must be careful, as extrapolating low-dimensional intuitions to higher dimensions can lead to un-
reliable conclusions. The difﬁculty of understanding high-dimensional landscapes notwithstanding,
it is the lot of neural network researchers to spend their efforts leading (or following?) networks

∗Work performed as an intern at Uber AI Labs.

1

