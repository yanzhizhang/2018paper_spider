Published as a conference paper at ICLR 2018

GENERALIZING HAMILTONIAN MONTE CARLO WITH
NEURAL NETWORKS

Daniel Levy1∗, Matthew D. Hoffman2, Jascha Sohl-Dickstein3
1Stanford University, 2Google AI Perception , 3Google Brain
danilevy@cs.stanford.edu, {mhoffman,jaschasd}@google.com

ABSTRACT

We present a general-purpose method to train Markov chain Monte Carlo ker-
nels, parameterized by deep neural networks, that converge and mix quickly to
their target distribution. Our method generalizes Hamiltonian Monte Carlo and is
trained to maximize expected squared jumped distance, a proxy for mixing speed.
We demonstrate large empirical gains on a collection of simple but challenging
distributions, for instance achieving a 106× improvement in effective sample size
in one case, and mixing when standard HMC makes no measurable progress in a
second. Finally, we show quantitative and qualitative gains on a real-world task:
latent-variable generative modeling. We release an open source TensorFlow im-
plementation of the algorithm.

1

INTRODUCTION

High-dimensional distributions that are only analytically tractable up to a normalizing constant are
ubiquitous in many ﬁelds. For instance, they arise in protein folding (Sch¨utte et al., 1999), physics
simulations (Olsson, 1995), and machine learning (Andrieu et al., 2003). Sampling from such dis-
tributions is a critical task for learning and inference (MacKay, 2003), however it is an extremely
hard problem in general.
Markov Chain Monte Carlo (MCMC) methods promise a solution to this problem. They operate
by generating a sequence of correlated samples that converge in distribution to the target. This
convergence is most often guaranteed through detailed balance, a sufﬁcient condition for the chain
to have the target equilibrium distribution. In practice, for any proposal distribution, one can ensure
detailed balance through a Metropolis-Hastings (Hastings, 1970) accept/reject step.
Despite theoretical guarantees of eventual convergence, in practice convergence and mixing speed
depend strongly on choosing a proposal that works well for the task at hand. What’s more, it is
often more art than science to know when an MCMC chain has converged (“burned-in”), and when
the chain has produced a new uncorrelated sample (“mixed”). Additionally, the reliance on detailed
balance, which assigns equal probability to the forward and reverse transitions, often encourages
random-walk behavior and thus slows exploration of the space (Ichiki & Ohzeki, 2013).
For densities over continuous spaces, Hamiltonian Monte Carlo (HMC; Duane et al., 1987; Neal,
2011) introduces independent, auxiliary momentum variables, and computes a new state by inte-
grating Hamiltonian dynamics. This method can traverse long distances in state space with a single
Metropolis-Hastings test. This is the state-of-the-art method for sampling in many domains. How-
ever, HMC can perform poorly in a number of settings. While HMC mixes quickly spatially, it
struggles at mixing across energy levels due to its volume-preserving dynamics. HMC also does
not work well with multi-modal distributions, as the probability of sampling a large enough mo-
mentum to traverse a very low-density region is negligibly small. Furthermore, HMC struggles with
ill-conditioned energy landscapes (Girolami & Calderhead, 2011) and deals poorly with rapidly
changing gradients (Sohl-Dickstein et al., 2014).
Recently, probabilistic models parameterized by deep neural networks have achieved great success
at approximately sampling from highly complex, multi-modal empirical distributions (Kingma &

∗Work was done while the author was at Google Brain.

1

