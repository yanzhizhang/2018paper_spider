Published as a conference paper at ICLR 2018

COULOMB GANS: PROVABLY OPTIMAL NASH EQUI-
LIBRIA VIA POTENTIAL FIELDS

Thomas Unterthiner1

Bernhard Nessler1

Calvin Seward1,2

Günter Klambauer1

Martin Heusel1

Hubert Ramsauer1

Sepp Hochreiter1

1LIT AI Lab & Institute of Bioinformatics, Johannes Kepler University Linz, Austria
2Zalando Research, Mühlenstraße 25, 10243 Berlin, Germany
{unterthiner,nessler,seward,klambauer,mhe,ramsauer,hochreit}@bioinf.jku.at

ABSTRACT

Generative adversarial networks (GANs) evolved into one of the most success-
ful unsupervised techniques for generating realistic images. Even though it has
recently been shown that GAN training converges, GAN models often end up
in local Nash equilibria that are associated with mode collapse or otherwise fail
to model the target distribution. We introduce Coulomb GANs, which pose the
GAN learning problem as a potential ﬁeld, where generated samples are attracted
to training set samples but repel each other. The discriminator learns a potential
ﬁeld while the generator decreases the energy by moving its samples along the
vector (force) ﬁeld determined by the gradient of the potential ﬁeld. Through de-
creasing the energy, the GAN model learns to generate samples according to the
whole target distribution and does not only cover some of its modes. We prove
that Coulomb GANs possess only one Nash equilibrium which is optimal in the
sense that the model distribution equals the target distribution. We show the ef-
ﬁcacy of Coulomb GANs on LSUN bedrooms, CelebA faces, CIFAR-10 and the
Google Billion Word text generation.

1

INTRODUCTION

Generative adversarial networks (GANs) (Goodfellow et al., 2014) excel at constructing realistic
images (Radford et al., 2016; Ledig et al., 2016; Isola et al., 2017; Arjovsky et al., 2017; Berthelot
et al., 2017) and text (Gulrajani et al., 2017). In GAN learning, a discriminator network guides the
learning of another, generative network. This procedure can be considered as a game between the
generator which constructs synthetic data and the discriminator which separates synthetic data from
training set data (Goodfellow, 2017). The generator’s goal is to construct data which the discrim-
inator cannot tell apart from training set data. GAN convergence points are local Nash equilibria.
At these local Nash equilibria neither the discriminator nor the generator can locally improve its
objective.
Despite their recent successes, GANs have several problems. First (I), until recently it was not clear
if in general gradient-based GAN learning could converge to one of the local Nash equilibria (Sal-
imans et al., 2016; Goodfellow, 2014; Goodfellow et al., 2014). It is even possible to construct
counterexamples (Goodfellow, 2017). Second (II), GANs suffer from “mode collapsing”, where the
model generates samples only in certain regions which are called modes. While these modes contain
realistic samples, the variety is low and only a few prototypes are generated. Mode collapsing is less
likely if the generator is trained with batch normalization, since the network is bound to create a
certain variance among its generated samples within one batch (Radford et al., 2016; Chintala et al.,
2016). However batch normalization introduces ﬂuctuations of normalizing constants which can be
harmful (Klambauer et al., 2017; Goodfellow, 2017). To avoid mode collapsing without batch nor-
malization, several methods have been proposed (Che et al., 2017; Metz et al., 2016; Salimans et al.,

1

