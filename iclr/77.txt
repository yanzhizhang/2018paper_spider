Published as a conference paper at ICLR 2018

COMPOSITIONAL OBVERTER COMMUNICATION
LEARNING FROM RAW VISUAL INPUT

Edward Choi ∗
Georgia Institute of Technology
Atlanta, GA, USA
mp2893@gatech.edu

Angeliki Lazaridou & Nando de Freitas
DeepMind
London, UK
{angeliki, nandodefreitas}@google.com

ABSTRACT

One of the distinguishing aspects of human language is its compositionality, which
allows us to describe complex environments with limited vocabulary. Previously, it
has been shown that neural network agents can learn to communicate in a highly
structured, possibly compositional language based on disentangled input (e.g. hand-
engineered features). Humans, however, do not learn to communicate based on
well-summarized features. In this work, we train neural agents to simultaneously
develop visual perception from raw image pixels, and learn to communicate with a
sequence of discrete symbols. The agents play an image description game where
the image contains factors such as colors and shapes. We train the agents using the
obverter technique where an agent introspects to generate messages that maximize
its own understanding. Through qualitative analysis, visualization and a zero-shot
test, we show that the agents can develop, out of raw image pixels, a language with
compositional properties, given a proper pressure from the environment.

1

INTRODUCTION

One of the key requirements for artiﬁcial general intelligence (AGI) to thrive in the real world is its
ability to communicate with humans in natural language. Natural language processing (NLP) has been
an active ﬁeld of research for a long time, and the introduction of deep learning (LeCun et al., 2015)
enabled great progress in NLP tasks such as translation, image captioning, text generation and visual
question answering (Cho et al., 2014; Bahdanau et al., 2014; Vinyals et al., 2015; Karpathy & Fei-Fei,
2015; Hu et al., 2017; Serban et al., 2016; Lewis et al., 2017; Antol et al., 2015). However, training
machines in a supervised manner with a large dataset has its limits when it comes to communication.
Supervised methods are effective for capturing statistical associations between discrete symbols (i.e.
words, letters). The essence of communication is more than just predicting the most likely word to
come next; it is a means to coordinate with others and potentially achieve a common goal (Austin,
1975; Clark, 1996; Wittgenstein, 1953).
An alternative path to teaching machines the art of communication is to give them a speciﬁc task and
encourage them to learn how to communicate on their own. This approach will encourage the agents
to use languages grounded to task-related entities as well as communicate with other agents, which
is one of the ways humans learn to communicate (Bruner, 1981). Recently, there have been several
notable works that demonstrated the emergence of communication between neural network agents.
Even though each work produced very interesting results of its own, in all cases, communication was
either achieved with a single discrete symbol (as opposed to a sequence of discrete symbols) (Foerster
et al., 2016; Lazaridou et al., 2017) or via a continuous value (Sukhbaatar et al., 2016; Jorge et al.,
2016). Not only is human communication un-differentiable, but also using a single discrete symbol is
quite far from natural language communication. One of the key features of human language is its
compositional nature; the meaning of a complex expression is determined by its structure and the
meanings of its constituents (Frege, 1892). More recently, Mordatch & Abbeel (2017) and Kottur
et al. (2017) trained the agents to communicate in grounded, compositional language. In both studies,
however, inputs given to the agents were hand-engineered features (disentangled input) rather than
raw perceptual signals that we receive as humans.

∗Work done as an intern at DeepMind.

1

