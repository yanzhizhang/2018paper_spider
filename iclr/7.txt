Published as a conference paper at ICLR 2018

LEARN TO PAY ATTENTION

Saumya Jetley, Nicholas A. Lord, Namhoon Lee & Philip H. S. Torr
Department of Engineering Science, University of Oxford
{sjetley,nicklord,namhoon,phst}@robots.ox.ac.uk

ABSTRACT

We propose an end-to-end-trainable attention module for convolutional neural net-
work (CNN) architectures built for image classiﬁcation. The module takes as in-
put the 2D feature vector maps which form the intermediate representations of
the input image at different stages in the CNN pipeline, and outputs a 2D ma-
trix of scores for each map. Standard CNN architectures are modiﬁed through
the incorporation of this module, and trained under the constraint that a convex
combination of the intermediate 2D feature vectors, as parameterised by the score
matrices, must alone be used for classiﬁcation. Incentivised to amplify the rel-
evant and suppress the irrelevant or misleading, the scores thus assume the role
of attention values. Our experimental observations provide clear evidence to this
effect: the learned attention maps neatly highlight the regions of interest while
suppressing background clutter. Consequently, the proposed function is able to
bootstrap standard CNN architectures for the task of image classiﬁcation, demon-
strating superior generalisation over 6 unseen benchmark datasets. When bina-
rised, our attention maps outperform other CNN-based attention maps, traditional
saliency maps, and top object proposals for weakly supervised segmentation as
demonstrated on the Object Discovery dataset. We also demonstrate improved
robustness against the fast gradient sign method of adversarial attack.

1

INTRODUCTION

Feed-forward convolutional neural networks (CNNs) have demonstrated impressive results on a
wide variety of visual tasks, such as image classiﬁcation, captioning, segmentation, and object de-
tection. However, the visual reasoning which they implement in solving these problems remains
largely inscrutable, impeding understanding of their successes and failures alike.
One approach to visualising and interpreting the inner workings of CNNs is the attention map: a
scalar matrix representing the relative importance of layer activations at different 2D spatial loca-
tions with respect to the target task (Simonyan et al., 2013). This notion of a nonuniform spatial
distribution of relevant features being used to form a task-speciﬁc representation, and the explicit
scalar representation of their relative relevance, is what we term ‘attention’. Previous works have
shown that for a classiﬁcation CNN trained using image-level annotations alone, extracting the atten-
tion map provides a straightforward way of determining the location of the object of interest (Cao
et al., 2015; Zhou et al., 2016) and/or its segmentation mask (Simonyan et al., 2013), as well as
helping to identify discriminative visual properties across classes (Zhou et al., 2016). More recently,
it has also been shown that training smaller networks to mimic the attention maps of larger and
higher-performing network architectures can lead to gains in classiﬁcation accuracy of those smaller
networks (Zagoruyko & Komodakis, 2016).
The works of Simonyan et al. (2013); Cao et al. (2015); Zhou et al. (2016) represent one series of in-
creasingly sophisticated techniques for estimating attention maps in classiﬁcation CNNs. However,
these approaches share a crucial limitation: all are implemented as post-hoc additions to fully trained
networks. On the other hand, integrated attention mechanisms whose parameters are learned over
the course of end-to-end training of the entire network have been proposed, and have shown beneﬁts
in various applications that can leverage attention as a cue. These include attribute prediction (Seo
et al., 2016), machine translation (Bahdanau et al., 2014), image captioning (Xu et al., 2015; You
et al., 2016; Mun et al., 2016) and visual question answering (VQA) (Xu & Saenko, 2016; Yang
et al., 2016). Similarly to these approaches, we here represent attention as a probabilistic map over

1

