Published as a conference paper at ICLR 2018

DEEP LEARNING WITH LOGGED BANDIT FEEDBACK

Thorsten Joachims
Cornell University
tj@cs.cornell.edu

Adith Swaminathan
Microsoft Research
adswamin@microsoft.com

Maarten de Rijke
University of Amsterdam
derijke@uva.nl

ABSTRACT

We propose a new output layer for deep neural networks that permits the use of
logged contextual bandit feedback for training. Such contextual bandit feedback
can be available in huge quantities (e.g., logs of search engines, recommender sys-
tems) at little cost, opening up a path for training deep networks on orders of mag-
nitude more data. To this effect, we propose a counterfactual risk minimization
approach for training deep networks using an equivariant empirical risk estima-
tor with variance regularization, BanditNet, and show how the resulting objective
can be decomposed in a way that allows stochastic gradient descent training. We
empirically demonstrate the effectiveness of the method by showing how deep
networks – ResNets in particular – can be trained for object recognition without
conventionally labeled images.

1

INTRODUCTION

Log data can be recorded from online systems such as search engines, recommender systems, or
online stores at little cost and in huge quantities. For concreteness, consider the interaction logs
of an ad-placement system for banner ads. Such logs typically contain a record of the input to the
system (e.g., features describing the user, banner ad, and page), the action that was taken by the
system (e.g., a speciﬁc banner ad that was placed) and the feedback furnished by the user (e.g.,
clicks on the ad, or monetary payoff). This feedback, however, provides only partial information
– “contextual-bandit feedback” – limited to the actions taken by the system. We do not get to see
how the user would have responded, if the system had chosen a different action (e.g., other ads or
banner types). Thus, the feedback for all other actions the system could have taken is typically
not known. This makes learning from log data fundamentally different from traditional supervised
learning, where “correct” predictions and a loss function provide feedback for all actions.
In this paper, we propose a new output layer for deep neural networks that allows training on logged
contextual bandit feedback. By circumventing the need for full-information feedback, our approach
opens a new and intriguing pathway for acquiring knowledge at unprecedented scale, giving deep
neural networks access to this abundant and ubiquitous type of data. Similarly, it enables the appli-
cation of deep learning even in domains where manually labeling full-information feedback is not
viable.
In contrast to online learning with contextual bandit feedback (e.g., (Williams, 1992; Agarwal et al.,
2014)), we perform batch learning from bandit feedback (BLBF) (Beygelzimer & Langford, 2009;
Swaminathan & Joachims, 2015a;b;c) and the algorithm does not require the ability to make inter-
active interventions. At the core of the new output layer for BLBF training of deep neural networks
lies a counterfactual training objective that replaces the conventional cross-entropy objective. Our
approach – called BanditNet – follows the view of a deep neural network as a stochastic policy.
We propose a counterfactual risk minimization (CRM) objective that is based on an equivariant
estimator of the true error that only requires propensity-logged contextual bandit feedback. This
makes our training objective fundamentally different from the conventional cross-entropy objective
for supervised classiﬁcation, which requires full-information feedback. Equivariance in our context
means that the learning result is invariant to additive translations of the loss, and it is more formally
deﬁned in Section 3.2. To enable large-scale training, we show how this training objective can be
decomposed to allow stochastic gradient descent (SGD) optimization.
In addition to the theoretical derivation of BanditNet, we present an empirical evaluation that veriﬁes
the applicability of the theoretical argument. It demonstrates how a deep neural network architec-

1

