Published as a conference paper at ICLR 2018

RETHINKING THE SMALLER-NORM-LESS-
INFORMATIVE ASSUMPTION IN CHANNEL PRUNING
OF CONVOLUTION LAYERS

Jianbo Ye∗
College of Information Sciences and Technology
The Pennsylvania State University
jxy198@ist.psu.edu

James Z. Wang
College of Information Sciences and Technology
The Pennsylvania State University
jwang@ist.psu.edu

Xin Lu, Zhe Lin
Adobe Research
{xinl,zlin}@adobe.com

ABSTRACT

Model pruning has become a useful technique that improves the computational
efﬁciency of deep learning, making it possible to deploy solutions in resource-
limited scenarios. A widely-used practice in relevant work assumes that a smaller-
norm parameter or feature plays a less informative role at the inference time. In
this paper, we propose a channel pruning technique for accelerating the computa-
tions of deep convolutional neural networks (CNNs) that does not critically rely
on this assumption. Instead, it focuses on direct simpliﬁcation of the channel-to-
channel computation graph of a CNN without the need of performing a computa-
tionally difﬁcult and not-always-useful task of making high-dimensional tensors
of CNN structured sparse. Our approach takes two stages: ﬁrst to adopt an end-to-
end stochastic training method that eventually forces the outputs of some channels
to be constant, and then to prune those constant channels from the original neural
network by adjusting the biases of their impacting layers such that the resulting
compact model can be quickly ﬁne-tuned. Our approach is mathematically appeal-
ing from an optimization perspective and easy to reproduce. We experimented our
approach through several image learning benchmarks and demonstrate its interest-
ing aspects and competitive performance.

1

INTRODUCTION

Not all computations in a deep neural network are of equal importance. In a typical deep learning
pipeline, an expert crafts a neural architecture, which is trained using a prepared dataset. The suc-
cess of training a deep model often requires trial and error, and such loop usually has little control
on prioritizing the computations happening in the neural network. Recently researchers started to
develop model-simpliﬁcation methods for convolutional neural networks (CNNs), bearing in mind
that some computations are indeed non-critical or redundant and hence can be safely removed from
a trained model without substantially degrading the model’s performance. Such methods not only
accelerate computational efﬁciency but also possibly alleviate the model’s overﬁtting effects.
Discovering which subsets of the computations of a trained CNN are more reasonable to prune,
however, is nontrivial. Existing methods can be categorized from either the learning perspective
or from the computational perspective. From the learning perspective, some methods use a data-
independent approach where the training data does not assist in determining which part of a trained
CNN should be pruned, e.g. He et al. (2017) and Zhang et al. (2016), while others use a data-
dependent approach through typically a joint optimization in generating pruning decisions, e.g., Han
et al. (2015) and Anwar et al. (2017). From the computational perspective, while most approaches

∗The research was done when J. Ye was an intern at Adobe in the summer of 2017.

1

