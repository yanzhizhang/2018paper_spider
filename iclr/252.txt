Published as a conference paper at ICLR 2018

N2N LEARNING: NETWORK TO NETWORK
COMPRESSION VIA POLICY GRADIENT
REINFORCEMENT LEARNING

Anubhav Ashok
Robotics Institute
Carnegie Mellon University
bhav@cmu.edu

Nicholas Rhinehart
Robotics Institute
Carnegie Mellon University
nrhineha@cs.cmu.edu

Fares Beainy
Volvo Construction Equipment
Volvo Group
fares.beainy@volvo.com

Kris M. Kitani
Robotics Institute
Carnegie Mellon University
kkitani@cs.cmu.edu

ABSTRACT

While wider and deeper neural network architectures continue to advance the
state-of-the-art for many computer vision tasks, real-world adoption of these net-
works is impeded by hardware and speed constraints. Conventional model com-
pression methods attempt to address this problem by modifying the architecture
manually or using pre-deﬁned heuristics. Since the space of all reduced architec-
tures is very large, modifying the architecture of a deep neural network in this way
is a difﬁcult task. In this paper, we tackle this issue by introducing a principled
method for learning reduced network architectures in a data-driven way using re-
inforcement learning. Our approach takes a larger ‘teacher’ network as input and
outputs a compressed ‘student’ network derived from the ‘teacher’ network. In the
ﬁrst stage of our method, a recurrent policy network aggressively removes layers
from the large ‘teacher’ model. In the second stage, another recurrent policy net-
work carefully reduces the size of each remaining layer. The resulting network is
then evaluated to obtain a reward – a score based on the accuracy and compression
of the network. Our approach uses this reward signal with policy gradients to train
the policies to ﬁnd a locally optimal student network. Our experiments show that
we can achieve compression rates of more than 10× for models such as ResNet-
34 while maintaining similar performance to the input ‘teacher’ network. We also
present a valuable transfer learning result which shows that policies which are
pre-trained on smaller ‘teacher’ networks can be used to rapidly speed up training
on larger ‘teacher’ networks.

1

INTRODUCTION

While carefully hand-designed deep convolutional networks continue to increase in size and in per-
formance, they also require signiﬁcant power, memory and computational resources, often to the
point of prohibiting their deployment on smaller devices. As a result, researchers have developed
model compression techniques based on Knowledge Distillation to compress a large (teacher) net-
work to a smaller (student) network using various training techniques (e.g., soft output matching,
hint layer matching, uncertainty modeling). Unfortunately, state-of-the-art knowledge distillation
methods share a common feature: they require carefully hand-designed architectures for the student
model. Hand-designing networks is a tedious sequential process, often loosely guided by a sequence
of trial-and-error based decisions to identify a smaller network architecture. This process makes it
very difﬁcult to know if the resulting network is optimal. Clearly, there is a need to develop more
principled methods of identifying optimal student architectures.

1

