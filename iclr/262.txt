Published as a conference paper at ICLR 2018

TRAINING AND INFERENCE WITH INTEGERS IN DEEP
NEURAL NETWORKS

Shuang Wu1, Guoqi Li1, Feng Chen2, Luping Shi1
1Department of Precision Instrument
2Department of Automation
Center for Brain Inspired Computing Research
Beijing Innovation Center for Future Chip
Tsinghua University
{lpshi,chenfeng}@mail.tsinghua.edu.cn

ABSTRACT

Researches on deep neural networks with discrete parameters and their deploy-
ment in embedded systems have been active and promising topics. Although pre-
vious works have successfully reduced precision in inference, transferring both
training and inference processes to low-bitwidth integers has not been demon-
strated simultaneously.
In this work, we develop a new method termed as
“WAGE” to discretize both training and inference, where weights (W), activations
(A), gradients (G) and errors (E) among layers are shifted and linearly constrained
to low-bitwidth integers. To perform pure discrete dataﬂow for ﬁxed-point de-
vices, we further replace batch normalization by a constant scaling layer and sim-
plify other components that are arduous for integer implementation. Improved ac-
curacies can be obtained on multiple datasets, which indicates that WAGE some-
how acts as a type of regularization. Empirically, we demonstrate the potential
to deploy training in hardware systems such as integer-based deep learning ac-
celerators and neuromorphic chips with comparable accuracy and higher energy
efﬁciency, which is crucial to future AI applications in variable scenarios with
transfer and continual learning demands.

1

INTRODUCTION

Recently deep neural networks (DNNs) are being widely used for numerous AI applications
(Krizhevsky et al., 2012; Hinton et al., 2012; Silver et al., 2016). Depending on the massive tunable
parameters, DNNs are considered to have powerful multi-level feature extraction and representation
abilities. However, training DNNs needs energy-intensive devices such as GPU and CPU with high
precision (ﬂoat32) processing units and abundant memory, which has greatly challenged their exten-
sive applications for portable devices. In addition, a state-of-art network often has far more weights
and effective capacity to shatter all training samples (Zhang et al., 2016), leading to overﬁtting easily.
As a result, there is much interest in reducing the size of network during inference (Hubara et al.,
2016; Rastegari et al., 2016; Li et al., 2016), as well as dedicated hardware for commercial solutions
(Jouppi et al., 2017; Chen et al., 2017; Shi et al., 2015). Due to the accumulation in stochastic gradi-
ent descent (SGD) optimization, the precision demand for training is usually higher than inference
(Hubara et al., 2016; Li et al., 2017). Therefore, most of the existing techniques only focus on the
deployment of a well-trained compressed network, while still keeping high precision and compu-
tational complexity during training. In this work, we address this problem as how to process both
training and inference with low-bitwidth integers, which is essential for implementing DNNs in ded-
icated hardware. To this end, two fundamental issues are addressed for discretely training DNNs: i)
how to quantize all the operands and operations, and ii) how many bits or states are needed for SGD
computation and accumulation.
With respect to the issues, we propose a framework termed as “WAGE” that constrains weights (W),
activations (A), gradients (G) and errors (E) among all layers to low-bitwidth integers in both training
and inference. Firstly, for operands, linear mapping and orientation-preserved shifting are applied

1

