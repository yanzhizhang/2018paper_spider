Published as a conference paper at ICLR 2018

PROGRESSIVE GROWING OF GANS FOR IMPROVED
QUALITY, STABILITY, AND VARIATION

Tero Karras
NVIDIA
{tkarras,taila,slaine,jlehtinen}@nvidia.com

Samuli Laine
NVIDIA

Timo Aila
NVIDIA

Jaakko Lehtinen
NVIDIA and Aalto University

ABSTRACT

We describe a new training methodology for generative adversarial networks. The
key idea is to grow both the generator and discriminator progressively: starting
from a low resolution, we add new layers that model increasingly ﬁne details as
training progresses. This both speeds the training up and greatly stabilizes it, al-
lowing us to produce images of unprecedented quality, e.g., CELEBA images at
10242. We also propose a simple way to increase the variation in generated im-
ages, and achieve a record inception score of 8.80 in unsupervised CIFAR10.
Additionally, we describe several implementation details that are important for
discouraging unhealthy competition between the generator and discriminator. Fi-
nally, we suggest a new metric for evaluating GAN results, both in terms of image
quality and variation. As an additional contribution, we construct a higher-quality
version of the CELEBA dataset.

INTRODUCTION

1
Generative methods that produce novel samples from high-dimensional data distributions, such as
images, are ﬁnding widespread use, for example in speech synthesis (van den Oord et al., 2016a),
image-to-image translation (Zhu et al., 2017; Liu et al., 2017; Wang et al., 2017), and image in-
painting (Iizuka et al., 2017). Currently the most prominent approaches are autoregressive models
(van den Oord et al., 2016b;c), variational autoencoders (VAE) (Kingma & Welling, 2014), and gen-
erative adversarial networks (GAN) (Goodfellow et al., 2014). Currently they all have signiﬁcant
strengths and weaknesses. Autoregressive models – such as PixelCNN – produce sharp images but
are slow to evaluate and do not have a latent representation as they directly model the conditional
distribution over pixels, potentially limiting their applicability. VAEs are easy to train but tend
to produce blurry results due to restrictions in the model, although recent work is improving this
(Kingma et al., 2016). GANs produce sharp images, albeit only in fairly small resolutions and with
somewhat limited variation, and the training continues to be unstable despite recent progress (Sali-
mans et al., 2016; Gulrajani et al., 2017; Berthelot et al., 2017; Kodali et al., 2017). Hybrid methods
combine various strengths of the three, but so far lag behind GANs in image quality (Makhzani &
Frey, 2017; Ulyanov et al., 2017; Dumoulin et al., 2016).
Typically, a GAN consists of two networks: generator and discriminator (aka critic). The generator
produces a sample, e.g., an image, from a latent code, and the distribution of these images should
ideally be indistinguishable from the training distribution. Since it is generally infeasible to engineer
a function that tells whether that is the case, a discriminator network is trained to do the assessment,
and since networks are differentiable, we also get a gradient we can use to steer both networks to
the right direction. Typically, the generator is of main interest – the discriminator is an adaptive loss
function that gets discarded once the generator has been trained.
There are multiple potential problems with this formulation. When we measure the distance between
the training distribution and the generated distribution, the gradients can point to more or less random
directions if the distributions do not have substantial overlap, i.e., are too easy to tell apart (Arjovsky
& Bottou, 2017). Originally, Jensen-Shannon divergence was used as a distance metric (Goodfellow
et al., 2014), and recently that formulation has been improved (Hjelm et al., 2017) and a number of
more stable alternatives have been proposed, including least squares (Mao et al., 2016b), absolute
deviation with margin (Zhao et al., 2017), and Wasserstein distance (Arjovsky et al., 2017; Gulrajani

1

