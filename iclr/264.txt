Published as a conference paper at ICLR 2018

CASCADE ADVERSARIAL MACHINE LEARNING REG-
ULARIZED WITH A UNIFIED EMBEDDING

Taesik Na, Jong Hwan Ko & Saibal Mukhopadhyay
School of Electrical and Computer Engineering
Georgia Institute of Technology
Atlanta, GA 30332, USA
{taesik.na, jonghwan.ko, smukhopadhyay6}@gatech.edu

ABSTRACT

Injecting adversarial examples during training, known as adversarial training, can
improve robustness against one-step attacks, but not for unknown iterative at-
tacks. To address this challenge, we ﬁrst show iteratively generated adversarial
images easily transfer between networks trained with the same strategy. Inspired
by this observation, we propose cascade adversarial training, which transfers the
knowledge of the end results of adversarial training. We train a network from
scratch by injecting iteratively generated adversarial images crafted from already
defended networks in addition to one-step adversarial images from the network
being trained. We also propose to utilize embedding space for both classiﬁcation
and low-level (pixel-level) similarity learning to ignore unknown pixel level per-
turbation. During training, we inject adversarial images without replacing their
corresponding clean images and penalize the distance between the two embed-
dings (clean and adversarial). Experimental results show that cascade adversarial
training together with our proposed low-level similarity learning efﬁciently en-
hances the robustness against iterative attacks, but at the expense of decreased ro-
bustness against one-step attacks. We show that combining those two techniques
can also improve robustness under the worst case black box attack scenario.

1

INTRODUCTION

Injecting adversarial examples during training (adversarial training), (Goodfellow et al., 2015; Ku-
rakin et al., 2017; Huang et al., 2015) increases the robustness of a network against adversarial
attacks. The networks trained with one-step methods have shown noticeable robustness against one-
step attacks, but, limited robustness against iterative attacks at test time. To address this challenge,
we have made the following contributions:
Cascade adversarial training: We ﬁrst show that iteratively generated adversarial images transfer
well between networks when the source and the target networks are trained with the same training
method. Inspired by this observation, we propose cascade adversarial training which transfers the
knowledge of the end results of adversarial training. In particular, we train a network by injecting
iter FGSM images (section 2.1) crafted from an already defended network (a network trained with
adversarial training) in addition to the one-step adversarial images crafted from the network being
trained. The concept of using already trained networks for adversarial training is also introduced in
(Tram`er et al., 2017). In their work, purely trained networks are used as another source networks
to generate one-step adversarial examples for training. On the contrary, our cascade adversarial
training uses already defended network for iter FGSM images generation.
Low level similarity learning: We advance the previous data augmentation approach (Kurakin
et al., 2017) by adding additional regularization in deep features to encourage a network to be insen-
sitive to adversarial perturbation. In particular, we inject adversarial images in the mini batch with-
out replacing their corresponding clean images and penalize distance between embeddings from the
clean and the adversarial examples. There are past examples of using embedding space for learning
similarity of high level features like face similarity between two different images (Schroff et al.,
2015; Parkhi et al., 2015; Wen et al., 2016).
Instead, we use the embedding space for learning

1

