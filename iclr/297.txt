Published as a conference paper at ICLR 2018

WHEN IS A CONVOLUTIONAL FILTER EASY TO
LEARN?

Simon S. Du
Carnegie Mellon University
ssdu@cs.cmu.edu

Jason D. Lee
University of Southern California
jasonlee@marshall.usc.edu

Yuandong Tian
Facebook AI Research
yuandong@fb.com

ABSTRACT

We analyze the convergence of (stochastic) gradient descent algorithm for learn-
ing a convolutional ﬁlter with Rectiﬁed Linear Unit (ReLU) activation function.
Our analysis does not rely on any speciﬁc form of the input distribution and our
proofs only use the deﬁnition of ReLU, in contrast with previous works that are
restricted to standard Gaussian input. We show that (stochastic) gradient descent
with random initialization can learn the convolutional ﬁlter in polynomial time
and the convergence rate depends on the smoothness of the input distribution and
the closeness of patches. To the best of our knowledge, this is the ﬁrst recovery
guarantee of gradient-based algorithms for convolutional ﬁlter on non-Gaussian
input distributions. Our theory also justiﬁes the two-stage learning rate strategy in
deep neural networks. While our focus is theoretical, we also present experiments
that justify our theoretical ﬁndings.

1

INTRODUCTION

Deep convolutional neural networks (CNN) have achieved the state-of-the-art performance in
many applications such as computer vision (Krizhevsky et al., 2012), natural language process-
ing (Dauphin et al., 2016) and reinforcement learning applied in classic games like Go (Silver et al.,
2016). Despite the highly non-convex nature of the objective function, simple ﬁrst-order algorithms
like stochastic gradient descent and its variants often train such networks successfully. On the other
hand, the success of convolutional neural network remains elusive from an optimization perspective.
When the input distribution is not constrained, existing results are mostly negative, such as hard-
ness of learning a 3-node neural network (Blum & Rivest, 1989) or a non-overlap convolutional
ﬁlter (Brutzkus & Globerson, 2017). Recently, Shamir (2016) showed learning a simple one-layer
fully connected neural network is hard for some speciﬁc input distributions.
These negative results suggest that, in order to explain the empirical success of SGD for learning
neural networks, stronger assumptions on the input distribution are needed. Recently, a line of
research (Tian, 2017; Brutzkus & Globerson, 2017; Li & Yuan, 2017; Soltanolkotabi, 2017; Zhong
et al., 2017) assumed the input distribution be standard Gaussian N (0, I) and showed (stochastic)
gradient descent is able to recover neural networks with ReLU activation in polynomial time.
One major issue of these analysis is that they rely on specialized analytic properties of the Gaussian
distribution (c.f. Section 1.1) and thus cannot be generalized to the non-Gaussian case, in which
real-world distributions fall into. For general input distributions, new techniques are needed.
In this paper we consider a simple architecture: a convolution layer, followed by a ReLU activation
function, and then average pooling. Formally, we let x ∈ Rd be an input sample, e.g., an image,
we generate k patches from x, each with size p: Z ∈ Rp×k where the i-th column is the i-th patch
generated by some known function Zi = Zi(x). For a ﬁlter with size 2 and stride 1, Zi(x) is the i-th
and (i + 1)-th pixels. Since for convolutional ﬁlters, we only need to focus on the patches instead
of the input, in the following deﬁnitions and theorems, we will refer Z as input and let Z as the
distribution of Z: (σ(x) = max(x, 0) is the ReLU activation function)

1

