Published as a conference paper at ICLR 2018

EMERGENT COMMUNICATION THROUGH
NEGOTIATION

Kris Cao∗
Department of Computer Science and Technology,
University of Cambridge, UK

Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls, Stephen Clark
DeepMind,
London, UK

ABSTRACT

Multi-agent reinforcement learning offers a way to study how communication
could emerge in communities of agents needing to solve speciﬁc problems. In this
paper, we study the emergence of communication in the negotiation environment,
a semi-cooperative model of agent interaction. We introduce two communication
protocols – one grounded in the semantics of the game, and one which is a priori
ungrounded and is a form of cheap talk. We show that self-interested agents can
use the pre-grounded communication channel to negotiate fairly, but are unable to
effectively use the ungrounded channel. However, prosocial agents do learn to use
cheap talk to ﬁnd an optimal negotiating strategy, suggesting that cooperation is
necessary for language to emerge. We also study communication behaviour in a
setting where one agent interacts with agents in a community with different levels
of prosociality and show how agent identiﬁability can aid negotiation.

1

INTRODUCTION

How can communication emerge? A necessary prerequisite is a task that requires coordination
between multiple agents to solve, and some communication protocol for the agents to exchange
messages through (see a review by Wagner et al. (2003) on earlier work on emergent communication
as well as recent deep reinforcement learning methods by Foerster et al. (2016) and Sukhbaatar et al.
(2016)). Given these basic requirements, an interesting question to ask is what task structures aid
the emergence of communication and how different communication protocols affect task success.
In the context of linguistic communication, previous work on this subject has mainly studied the
emergence of communication in co-operative games like referential games, variants of the Lewis
signaling game (Lewis, 1969), where messages are used to disambiguate between different possible
referents (Goldman et al., 2007; Lazaridou et al., 2016; Evtimova et al., 2017). Human language,
though, is not merely a referential tool. Amongst other things, we communicate private information
and thoughts, discuss plans, ask questions and tell jokes. Moreover, many human interactions are
not fully cooperative, yet we can still successfully use language to communicate in these situations.
In this paper, we study communication in the negotiation game (see Figure 1), an established model
of non-cooperative games in classical game theory (Nash, 1950b; Neumann & Morgenstern, 1944;
Nash, 1950a; 1951; Schelling, 1960; Binmore et al., 1986; Peters, 2008). In this game, agents are
asked to establish a mutually acceptable division of a common pool of items while having their
own hidden utilities for each of them. Effective communication is crucial in this game, as the
agents need to exchange strategic information about their desires, infer their opponent’s desires
from communication, and balance between the two.
Work in classical game theory on negotiation typically uses simple forms of offer / counter-offer
bargaining games that do not explicitly address the question of emergent communication (Rubin-
∗Work done during an internship at DeepMind. Correspondence to Kris Cao (kc391@cam.ac.uk) or

Angeliki Lazaridou (angeliki@google.com).

1

