Published as a conference paper at ICLR 2018

FEW-SHOT AUTOREGRESSIVE DENSITY ESTIMATION:
TOWARDS LEARNING TO LEARN DISTRIBUTIONS

S. Reed, Y. Chen, T. Paine, A. van den Oord, S. M. A. Eslami, D. Rezende, O. Vinyals, N. de Freitas
{reedscot,yutianc,tpaine}@google.com

ABSTRACT

Deep autoregressive models have shown state-of-the-art performance in density
estimation for natural images on large-scale datasets such as ImageNet. How-
ever, such models require many thousands of gradient-based weight updates and
unique image examples for training. Ideally, the models would rapidly learn vi-
sual concepts from only a handful of examples, similar to the manner in which
humans learns across many vision tasks. In this paper, we show how 1) neural
attention and 2) meta learning techniques can be used in combination with au-
toregressive models to enable effective few-shot density estimation. Our proposed
modiﬁcations to PixelCNN result in state-of-the art few-shot density estimation on
the Omniglot dataset. Furthermore, we visualize the learned attention policy and
ﬁnd that it learns intuitive algorithms for simple tasks such as image mirroring on
ImageNet and handwriting on Omniglot without supervision. Finally, we extend
the model to natural images and demonstrate few-shot image generation on the
Stanford Online Products dataset.

1

INTRODUCTION

Contemporary machine learning systems are still far behind humans in their ability to rapidly learn
new visual concepts from only a few examples (Lake et al., 2013). This setting, called few-shot
learning, has been studied using deep neural networks and many other approaches in the context of
discriminative models, for example Vinyals et al. (2016); Santoro et al. (2016). However, compara-
tively little attention has been devoted to the task of few-shot image density estimation; that is, the
problem of learning a model of a probability distribution from a small number of examples. Below
we motivate our study of few-shot autoregressive models, their connection to meta-learning, and
provide a comparison of multiple approaches to conditioning in neural density models.

WHY AUTOREGRESSIVE MODELS?

Autoregressive neural networks are useful for studying few-shot density estimation for several rea-
sons. They are fast and stable to train, easy to implement, and have tractable likelihoods, allowing
us to quantitatively compare a large number of model variants in an objective manner. Therefore we
can easily add complexity in orthogonal directions to the generative model itself.
Autoregressive image models factorize the joint distribution into per-pixel factors:

P (x|s; θ) =

P (xt|x<t, f (s); θ)

t=1

(1)
where θ are the model parameters, x ∈ RN are the image pixels, s is a conditioning variable, and f
is a function encoding this conditioning variable. For example in text-to-image synthesis, s would
be an image caption and f could be a convolutional or recurrent encoder network, as in Reed et al.
(2016). In label-conditional image generation, s would be the discrete class label and f could simply
convert s to a one-hot encoding possibly followed by an MLP.
A straightforward approach to few-shot density estimation would be to simply treat samples from
the target distribution as conditioning variables for the model. That is, let s correspond to a few data
examples illustrating a concept. For example, s may consist of four images depicting bears, and the
task is then to generate an image x of a bear, or to compute its probability P (x|s; θ).

N(cid:89)

1

