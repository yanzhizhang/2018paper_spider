Published as a conference paper at ICLR 2018

DEPTHWISE SEPARABLE CONVOLUTIONS FOR
NEURAL MACHINE TRANSLATION

Łukasz Kaiser∗
Google Brain
lukaszkaiser@google.com

François Chollet∗
Google Brain
fchollet@google.com

Aidan N. Gomez∗†
University of Toronto
aidan@cs.toronto.edu

ABSTRACT

Depthwise separable convolutions reduce the number of parameters and computa-
tion used in convolutional operations while increasing representational efﬁciency.
They have been shown to be successful in image classiﬁcation models, both in
obtaining better models than previously possible for a given parameter count
(the Xception architecture) and considerably reducing the number of parameters
required to perform at a given level (the MobileNets family of architectures). Re-
cently, convolutional sequence-to-sequence networks have been applied to machine
translation tasks with good results. In this work, we study how depthwise separable
convolutions can be applied to neural machine translation. We introduce a new
architecture inspired by Xception and ByteNet, called SliceNet, which enables a
signiﬁcant reduction of the parameter count and amount of computation needed to
obtain results like ByteNet, and, with a similar parameter count, achieves better
results. In addition to showing that depthwise separable convolutions perform well
for machine translation, we investigate the architectural changes that they enable:
we observe that thanks to depthwise separability, we can increase the length of
convolution windows, removing the need for ﬁlter dilation. We also introduce a
new "super-separable" convolution operation that further reduces the number of
parameters and computational cost of the models.

1

INTRODUCTION

In recent years, sequence-to-sequence recurrent neural networks (RNNs) with long short-term memory
(LSTM) cells (Hochreiter & Schmidhuber, 1997) have proven successful at many natural language
processing (NLP) tasks, including machine translation (Sutskever et al., 2014; Bahdanau et al., 2014;
Cho et al., 2014b). In fact, the results they yielded have been so good that the gap between human
translations and machine translations has narrowed signiﬁcantly (Wu et al., 2016) and LSTM-based
recurrent neural networks have become standard in natural language processing.
Even more recently, auto-regressive convolutional models have proven highly effective when applied
to audio (van den Oord et al., 2016a), image (van den Oord et al., 2016b) and text generation
(Kalchbrenner et al., 2016). Their success on sequence data in particular rivals or surpasses that of
previous recurrent models (Kalchbrenner et al., 2016; Gehring et al., 2017). Convolutions provide
the means for efﬁcient non-local referencing across time without the need for the fully sequential
processing of RNNs. However, a major critique of such models is their computational complexity
and large parameter count. These are the principal concerns addressed within this work: inspired by
the efﬁciency of depthwise separable convolutions demonstrated in the domain of vision, in particular
the Xception architecture (Chollet, 2016) and MobileNets (Howard et al., 2017), we generalize these
techniques and apply them to the language domain, with great success.

∗All authors contributed equally and are ordered randomly.
†Work performed while at Google Brain.
Code available at https://github.com/tensorflow/tensor2tensor

1

