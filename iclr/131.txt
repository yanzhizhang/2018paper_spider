Published as a conference paper at ICLR 2018

MINIMAX CURRICULUM LEARNING:
MACHINE TEACHING WITH DESIRABLE DIFFICULTIES
AND SCHEDULED DIVERSITY

Tianyi Zhou & Jeff Bilmes
University of Washington, Seattle
{tianyizh,bilmes}@uw.edu

ABSTRACT

We introduce and study minimax curriculum learning (MCL), a new method for
adaptively selecting a sequence of training subsets for a succession of stages in
machine learning. The subsets are encouraged to be small and diverse early on,
and then larger, harder, and allowably more homogeneous in later stages. At each
stage, model weights and training sets are chosen by solving a joint continuous-
discrete minimax optimization, whose objective is composed of a continuous loss
(reﬂecting training set hardness) and a discrete submodular promoter of diversity
for the chosen subset. MCL repeatedly solves a sequence of such optimizations
with a schedule of increasing training set size and decreasing pressure on diversity
encouragement. We reduce MCL to the minimization of a surrogate function han-
dled by submodular maximization and continuous gradient methods. We show that
MCL achieves better performance and, with a clustering trick, uses fewer labeled
samples for both shallow and deep models. Our method involves repeatedly solving
constrained submodular maximization of an only slowly varying function on the
same ground set. Therefore, we develop a heuristic method that utilizes the previ-
ous submodular maximization solution as a warm start for the current submodular
maximization process to reduce computation while still yielding a guarantee.

1

INTRODUCTION

Inspired by the human interaction between teacher and student, recent studies (Khan et al., 2011;
Basu & Christensen, 2013; Spitkovsky et al., 2009) support that learning algorithms can be improved
by updating a model on a designed sequence of training sets, i.e., a curriculum. This problem
is addressed in curriculum learning (CL) (Bengio et al., 2009), where the sequence is designed
by a human expert or heuristic before training begins. Instead of relying on a teacher to provide
the curriculum, self-paced learning (SPL) (Kumar et al., 2010; Tang et al., 2012a; Supancic III &
Ramanan, 2013; Tang et al., 2012b) chooses the curriculum during the training process. It does so by
letting the student (i.e., the algorithm) determine which samples to learn from based on their hardness.
Given a training set D = {(x1, y1), . . . , (xn, yn)} of n samples and loss function L(yi, f (xi, w)),
where xi ∈ Rm represents the feature vector for the ith sample, yi is its label, and f (xi, w) is the
predicted label provided by a model with weight w, SPL performs the following:

νiL (yi, f (xi, w)) − λ

νi

.

(1)

SPL jointly learns the model weights w and sample weights ν, which end up being 0-1 indicators
of selected samples, and it does so via alternating minimization. Fixing w, minimization w.r.t. ν
selects samples with loss L(yi, f (xi, w)) < λ, where λ is a “hardness parameter” as it corresponds
to the hardness as measure by the current loss (since with large λ, samples with greater loss are
allowed in). Self-paced curriculum learning (Jiang et al., 2015) introduces a blending of “teacher
mode” in CL and “student mode” in SPL, where the teacher can deﬁne a region of ν by attaching a
linear constraint aT ν ≤ c to Eq. (1). SPL with diversity (SPLD) (Jiang et al., 2014), adds to Eq. (1)
j=1 (cid:107)ν(j)(cid:107)2, where the samples are

a negative group sparse regularization term −γ(cid:107)ν(cid:107)2,1 (cid:44) −γ(cid:80)b

(cid:34) n(cid:88)

i=1

min
w∈Rm

min
ν∈[0,1]n

(cid:35)

n(cid:88)

i=1

1

