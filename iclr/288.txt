Published as a conference paper at ICLR 2018

GO FOR A WALK AND ARRIVE AT THE ANSWER:
REASONING OVER PATHS IN KNOWLEDGE BASES
USING REINFORCEMENT LEARNING

Rajarshi Das(cid:63),1, Shehzaad Dhuliawala(cid:63),1, Manzil Zaheer(cid:63),2
Luke Vilnis1, Ishan Durugkar3, Akshay Krishnamurthy1, Alex Smola4, Andrew McCallum1
{rajarshi, sdhuliawala, luke, akshay, mccallum}@cs.umass.edu
manzil@cmu.edu, ishand@cs.utexas.edu, alex@smola.org
1University of Massachusetts, Amherst, 2Carnegie Mellon University
3University of Texas at Austin, 4Amazon Web Services

ABSTRACT

Knowledge bases (KB), both automatically and manually constructed, are often
incomplete — many valid facts can be inferred from the KB by synthesizing
existing information. A popular approach to KB completion is to infer new relations
by combinatory reasoning over the information found along other paths connecting
a pair of entities. Given the enormous size of KBs and the exponential number of
paths, previous path-based models have considered only the problem of predicting
a missing relation given two entities, or evaluating the truth of a proposed triple.
Additionally, these methods have traditionally used random paths between ﬁxed
entity pairs or more recently learned to pick paths between them. We propose a new
algorithm, MINERVA, which addresses the much more difﬁcult and practical task of
answering questions where the relation is known, but only one entity. Since random
walks are impractical in a setting with unknown destination and combinatorially
many paths from a start node, we present a neural reinforcement learning approach
which learns how to navigate the graph conditioned on the input query to ﬁnd
predictive paths. On a comprehensive evaluation on seven knowledge base datasets,
we found MINERVA to be competitive with many current state-of-the-art methods.

1

INTRODUCTION

Automated reasoning, the ability of computing systems to make new inferences from observed
evidence, has been a long-standing goal of artiﬁcial intelligence. We are interested in automated
reasoning on large knowledge bases (KB) with rich and diverse semantics (Suchanek et al., 2007;
Bollacker et al., 2008; Carlson et al., 2010). KBs are highly incomplete (Min et al., 2013), and facts
not directly stored in a KB can often be inferred from those that are, creating exciting opportunities
and challenges for automated reasoning. For example, consider the small knowledge graph in
Figure 1. We can answer the question “Who did Malala Yousafzai share her Nobel Peace prize with?”
from the following reasoning path: Malala Yousafzai → WonAward → Nobel Peace Prize 2014 →
AwardedTo → Kailash Satyarthi. Our goal is to automatically learn such reasoning paths in KBs. We
frame the learning problem as one of query answering, that is to say, answering questions of the form
(Malala Yousafzai, SharesNobelPrizeWith, ?).
From its early days, the focus of automated reasoning approaches has been to build systems that can
learn crisp symbolic logical rules (McCarthy, 1960; Nilsson, 1991). Symbolic representations have
also been integrated with machine learning especially in statistical relational learning (Muggleton
et al., 1992; Getoor & Taskar, 2007; Kok & Domingos, 2007; Lao et al., 2011), but due to poor
generalization performance, these approaches have largely been superceded by distributed vector
representations. Learning embedding of entities and relations using tensor factorization or neural
methods has been a popular approach (Nickel et al., 2011; Bordes et al., 2013; Socher et al., 2013,
inter alia), but these methods cannot capture chains of reasoning expressed by KB paths. Neural
multi-hop models (Neelakantan et al., 2015; Guu et al., 2015; Toutanova et al., 2016) address the
aforementioned problems to some extent by operating on KB paths embedded in vector space.
However, these models take as input a set of paths which are gathered by performing random walks

1

