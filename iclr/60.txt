Published as a conference paper at ICLR 2018

LEVERAGING GRAMMAR AND REINFORCEMENT
LEARNING FOR NEURAL PROGRAM SYNTHESIS

Rudy Bunel∗
University of Oxford
rudy@robots.ox.ac.uk

Matthew Hausknecht
Microsoft Research
matthew.hausknecht@microsoft.com

Jacob Devlin∗
Google
jacobdevlin@google.com

Rishabh Singh
Microsoft Research
risin@microsoft.com

Pushmeet Kohli∗
Deepmind
pushmeet@google.com

ABSTRACT

Program synthesis is the task of automatically generating a program consistent with
a speciﬁcation. Recent years have seen proposal of a number of neural approaches
for program synthesis, many of which adopt a sequence generation paradigm similar
to neural machine translation, in which sequence-to-sequence models are trained to
maximize the likelihood of known reference programs. While achieving impressive
results, this strategy has two key limitations. First, it ignores Program Aliasing: the
fact that many different programs may satisfy a given speciﬁcation (especially with
incomplete speciﬁcations such as a few input-output examples). By maximizing
the likelihood of only a single reference program, it penalizes many semantically
correct programs, which can adversely affect the synthesizer performance. Second,
this strategy overlooks the fact that programs have a strict syntax that can be
efﬁciently checked. To address the ﬁrst limitation, we perform reinforcement
learning on top of a supervised model with an objective that explicitly maximizes
the likelihood of generating semantically correct programs. For addressing the
second limitation, we introduce a training procedure that directly maximizes the
probability of generating syntactically correct programs that fulﬁll the speciﬁcation.
We show that our contributions lead to improved accuracy of the models, especially
in cases where the training data is limited.

1

INTRODUCTION

The task of program synthesis is to automatically generate a program that is consistent with a
speciﬁcation such as a set of input-output examples, and has been studied since the early days of
Artiﬁcial Intelligence (Waldinger and Lee, 1969). There has been a lot of recent progress made on
neural program induction, where novel neural architectures inspired from computation modules such
as RAM, stack, CPU, turing machines, and GPU (Graves et al., 2014; Joulin and Mikolov, 2015;
Kurach et al., 2016; Graves et al., 2016; Reed and de Freitas, 2016; Kaiser and Sutskever, 2016)
have been proposed to train these architectures in an end-to-end fashion to mimic the behavior of the
desired program. While these approaches have achieved impressive results, they do not return explicit
interpretable programs, tend not to generalize well on inputs of arbitrary length, and require a lot of
examples and computation for learning each program. To mitigate some of these limitations, neural
program synthesis approaches (Johnson et al., 2017; Parisotto et al., 2017; Devlin et al., 2017b) have
been recently proposed that learn explicit programs in a Domain-speciﬁc language (DSL) from as
few as ﬁve input-output examples. These approaches, instead of using a large number of input-output
examples to learn a single program, learn a large number of different programs, each from just a few
input-output examples. During training, the correct program is provided as reference, but at test time,
the learnt model generates the program from only the input-output examples.
While neural program synthesis techniques improve over program induction techniques in certain
domains, they suffer from two key limitations. First, these approaches use supervised learning

∗Work performed at Microsoft Research

1

