Published as a conference paper at ICLR 2018

i-REVNET: DEEP INVERTIBLE NETWORKS

J¨orn-Henrik Jacobsen †‡, Arnold Smeulders †, Edouard Oyallon §
†University of Amsterdam
joern.jacobsen@bethgelab.org

ABSTRACT

It is widely believed that the success of deep convolutional networks is based on
progressively discarding uninformative variability about the input with respect to
the problem at hand. This is supported empirically by the difﬁculty of recovering
images from their hidden representations, in most commonly used network archi-
tectures. In this paper we show via a one-to-one mapping that this loss of infor-
mation is not a necessary condition to learn representations that generalize well
on complicated problems, such as ImageNet. Via a cascade of homeomorphic
layers, we build the i-RevNet, a network that can be fully inverted up to the ﬁnal
projection onto the classes, i.e. no information is discarded. Building an invertible
architecture is difﬁcult, for one, because the local inversion is ill-conditioned, we
overcome this by providing an explicit inverse. An analysis of i-RevNets learned
representations suggests an alternative explanation for the success of deep net-
works by a progressive contraction and linear separation with depth. To shed light
on the nature of the model learned by the i-RevNet we reconstruct linear interpo-
lations between natural image representations.

1

INTRODUCTION

A CNN may be very effective in classifying images of all sorts (He et al., 2016; Krizhevsky et al.,
2012), but the cascade of linear and nonlinear operators reveals little about the contribution of the
internal representation to the classiﬁcation. The learning process is characterized by a steady re-
duction of large amounts of uninformative variability in the images while simultaneously revealing
the essence of the visual class. It is widely believed that this process is based on progressively dis-
carding uninformative variability about the input with respect to the problem at hand (Dosovitskiy
& Brox, 2016; Mahendran & Vedaldi, 2016; Shwartz-Ziv & Tishby, 2017; Achille & Soatto, 2017).
However, the extent to which information is discarded is lost somewhere in the intermediate non-
linear processing steps. In this paper, we aim to provide insight into the variability reduction process
by proposing an invertible convolutional network, that does not discard any information about the
input.
The difﬁculty to recover images from their hidden representations is found in many commonly used
network architectures (Dosovitskiy & Brox, 2016; Mahendran & Vedaldi, 2016). This poses the
question if a substantial loss of information is necessary for successful classiﬁcation. We show
information does not have to be discarded. By using homeomorphic layers, the invariance can be
built only at the very last layer via a projection.
In Shwartz-Ziv & Tishby (2017), minimal sufﬁcient statistics are proposed as a candidate to explain
the reduction of variability. Tishby & Zaslavsky (2015) introduces the information bottleneck princi-
ple which states that an optimal representation must reduce the mutual information between an input
and its representation to reduce as much uninformative variability as possible. At the same time, the
network should maximize the mutual information between the desired output and its representation
to effectively preserve each class from collapsing onto other classes. The effect of the information
bottleneck was demonstrated on small datasets in Shwartz-Ziv & Tishby (2017); Achille & Soatto
(2017).

‡Now at Bethgelab, University of T¨ubingen
§CVN, CentraleSup´elec, Universit´e Paris-Saclay ; Galen team, INRIA Saclay

SequeL team, INRIA Lille ; DI, ENS, Universit´e PSL

1

